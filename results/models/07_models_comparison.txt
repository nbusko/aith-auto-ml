============================================================
СРАВНЕНИЕ ВСЕХ МОДЕЛЕЙ
============================================================

МЕТРИКИ ВСЕХ МОДЕЛЕЙ:
                model  roc_auc  accuracy  f1_score
pipeline_v1_optimized 0.997978  0.986000  0.986000
          pipeline_v2 0.996701  0.991000  0.991001
         lama_config1 0.996311  0.988700  0.988702
         lama_config2 0.996286  0.988563  0.988565
          pipeline_v1 0.984716  0.935000  0.935026


Лучшая модель: pipeline_v1_optimized
ROC-AUC: 0.997978

LAMA Baseline ROC-AUC: 0.996311

Лучшая модель ПРЕВОСХОДИТ LAMA baseline!
Рекомендация: Использовать лучшую модель для финального submission

ДЕТАЛЬНОЕ СРАВНЕНИЕ:

lama_config1:
  ROC-AUC: 0.996311
  Accuracy: 0.988700
  F1-Score: 0.988702

lama_config2:
  ROC-AUC: 0.996286
  Accuracy: 0.988563
  F1-Score: 0.988565

pipeline_v1:
  ROC-AUC: 0.984716
  Accuracy: 0.935000
  F1-Score: 0.935026

pipeline_v1_optimized:
  ROC-AUC: 0.997978
  Accuracy: 0.986000
  F1-Score: 0.986000

pipeline_v2:
  ROC-AUC: 0.996701
  Accuracy: 0.991000
  F1-Score: 0.991001